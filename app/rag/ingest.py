import os
import json
from typing import List
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings
from langchain_elasticsearch import ElasticsearchStore
from dotenv import load_dotenv

load_dotenv()

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
ELASTICSEARCH_URL = os.getenv("ELASTICSEARCH_URL", "http://localhost:9200")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
INDEX_NAME = "card_benefit_index_v1"  # ì¸ë±ìŠ¤ ì´ë¦„ ë³€ê²½ ê¶Œì¥

def load_processed_docs(json_path: str) -> List[Document]:
    """ì „ì²˜ë¦¬ëœ JSON íŒŒì¼ì„ ì½ì–´ LangChain Document ê°ì²´ë¡œ ë³€í™˜"""
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        documents = []
        for item in data:
            # page_contentì™€ metadataê°€ í™•ì‹¤íˆ ë¶„ë¦¬ë˜ì–´ ìˆì–´ì•¼ í•¨
            doc = Document(
                page_content=item["page_content"],
                metadata=item["metadata"]
            )
            documents.append(doc)
            
        print(f"âœ… JSONì—ì„œ {len(documents)}ê°œì˜ ë¬¸ì„œë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return documents
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise

def ingest_documents(docs: List[Document]):
    """Elasticsearchì— ë¬¸ì„œì™€ ë©”íƒ€ë°ì´í„° ì ì¬"""
    try:
        embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        
        print(f"ğŸš€ Elasticsearch({ELASTICSEARCH_URL})ì— ì ì¬ ì‹œì‘...")
        
        # from_documentsë¥¼ ì‚¬ìš©í•˜ë©´ metadataë„ ìë™ìœ¼ë¡œ ESì— ë§¤í•‘ë˜ì–´ ì €ì¥ë©ë‹ˆë‹¤.
        vector_store = ElasticsearchStore.from_documents(
            documents=docs,
            embedding=embeddings,
            es_url=ELASTICSEARCH_URL,
            index_name=INDEX_NAME,
            # ì´ë¯¸ ì²­í‚¹ì´ ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œ ë˜ ìë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.
        )
        
        print(f"ğŸ‰ ì ì¬ ì™„ë£Œ! ì´ {len(docs)}ê°œ ë¬¸ì„œê°€ '{INDEX_NAME}' ì¸ë±ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return vector_store
        
    except Exception as e:
        print(f"âŒ ì ì¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

if __name__ == "__main__":
    # ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ë§Œë“  íŒŒì¼ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”.
    JSON_FILE_PATH = "processed_card_chunks.json" 
    
    if os.path.exists(JSON_FILE_PATH):
        docs = load_processed_docs(JSON_FILE_PATH)
        ingest_documents(docs)
    else:
        print(f"âš ï¸ '{JSON_FILE_PATH}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì „ì²˜ë¦¬ ì½”ë“œë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì„œ íŒŒì¼ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.")