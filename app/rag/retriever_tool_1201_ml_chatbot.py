import os
import json
import logging
import requests
from typing import List, Dict, Any, Optional
from elasticsearch import Elasticsearch
from dotenv import load_dotenv

# [LangSmith] ì¶”ì ìš© ë°ì½”ë ˆì´í„° ì„í¬íŠ¸
try:
    from langsmith import traceable
except ImportError:
    # langsmithê°€ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ë”ë¯¸ ë°ì½”ë ˆì´í„°
    def traceable(**kwargs):
        def decorator(func):
            return func
        return decorator

# ë°ì´í„° ëª¨ë“ˆ Import ì²˜ë¦¬
try:
    from rag.data.category_mapping import map_codes_to_korean
    from rag.data.cluster_definitions import PERSONA_CLUSTERS
except ImportError:
    # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° (ì‹¤ì œ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
    def map_codes_to_korean(codes): return codes
    PERSONA_CLUSTERS = {
        0: {"name": "ì‚¬íšŒì´ˆë…„ìƒ", "avg_spend": 500000, "keywords": ["í¸ì˜ì ", "êµí†µ", "ì¹´í˜"]},
        1: {"name": "ì§ì¥ì¸", "avg_spend": 1500000, "keywords": ["ì£¼ìœ ", "ë§ˆíŠ¸", "ì ì‹¬"]}
    }

load_dotenv()

# ============================================================
# [LangSmith] ì„¤ì • ì ìš©
# ============================================================
def safe_print(msg):
    print(msg)

langsmith_api_key = os.getenv("LANGSMITH_API_KEY")
if langsmith_api_key:
    os.environ["LANGCHAIN_TRACING_V2"] = "true"
    os.environ["LANGCHAIN_API_KEY"] = langsmith_api_key
    os.environ["LANGCHAIN_PROJECT"] = "CardBenefit RAG Debug"  # í”„ë¡œì íŠ¸ëª…
    safe_print(f"âœ… LangSmith Tracing Enabled (Project: {os.environ['LANGCHAIN_PROJECT']})")
else:
    safe_print("âš ï¸ LangSmith API Key not found. Tracing disabled.")

safe_print(f"ğŸ” ìµœì¢… ê³ ë„í™” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (Score Breakdown Added)")
safe_print("ğŸ’¡ ì¢…ë£Œí•˜ë ¤ë©´ 'q' ì…ë ¥ ë˜ëŠ” Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.\n")

# ============================================================
# ì„¤ì •
# ============================================================
ELASTICSEARCH_URL = os.getenv("ELASTICSEARCH_URL", "http://localhost:9200")
INDEX_NAME = "credit_cards_nested_top100"
HF_API_KEY = os.getenv("HF_API_KEY")
MODEL_NAME = "meta-llama/Llama-3.1-8B-Instruct:novita"

logger = logging.getLogger("CardPipeline")
logger.setLevel(logging.INFO)

# ============================================================
# [Module 1] ê³µí†µ ìœ í‹¸ë¦¬í‹°
# ============================================================

class BenefitCalculator:
    """[ê³µí†µ] ì¹´ë“œ í˜œíƒ ê¸ˆì•¡ ê³„ì‚°ê¸°"""
    
    @staticmethod
    @traceable(run_type="tool", name="Benefit_Calculator") # LangSmith: ë„êµ¬ë¡œ ì¸ì‹
    def calculate(card_source: Dict, user_spend: int, preferred_keywords: List[str]) -> Dict:
        total_benefit_krw = 0
        matched_details = []

        for ben in card_source.get("benefits", []):
            summary = ben.get("summary", "")
            category = ben.get("category", "")
            tiers = ben.get("tiers", [])

            # 1. Tiers í™•ì¸
            sorted_tiers = sorted(tiers, key=lambda x: x.get("previous_min_spend", 0))
            applied_tier = None
            for tier in sorted_tiers:
                if user_spend >= tier.get("previous_min_spend", 0):
                    applied_tier = tier
                else:
                    break 
            
            if not applied_tier: continue

            # 2. ê¸ˆì•¡ ì‚°ì •
            val = 0
            if applied_tier.get("unit") == "%":
                val = (user_spend * 0.1) * applied_tier.get("rate", 0)
            elif applied_tier.get("unit") == "KRW":
                val = applied_tier.get("rate", 0)

            # 3. ê°€ì¤‘ì¹˜ ì ìš©
            is_preferred = any(pk in category or pk in summary for pk in preferred_keywords)
            if is_preferred:
                val *= 1.5
                matched_details.append(f"{category}(â˜…)")
            else:
                matched_details.append(category)
            
            total_benefit_krw += val

        return {"score": total_benefit_krw, "matched_info": ", ".join(list(set(matched_details)))}

class ESMultiRetriever:
    """[ê³µí†µ] Elasticsearch ê²€ìƒ‰ê¸°"""
    def __init__(self):
        print(f"ğŸ”Œ [ES] Connecting to {ELASTICSEARCH_URL}...")
        self.client = Elasticsearch(ELASTICSEARCH_URL)

    @traceable(run_type="retriever", name="ES_Search") # LangSmith: ê²€ìƒ‰ê¸°ë¡œ ì¸ì‹
    def search_by_coverage(self, keywords: List[str], size: int = 150) -> List[Dict]:
        print(f"ğŸ” [ES] Searching for keywords: {keywords}")
        should_clauses = []
        for kw in keywords:
            should_clauses.append({
                "nested": {
                    "path": "benefits",
                    "score_mode": "sum",
                    "query": {
                        "bool": {
                            "should": [
                                {"match": {"benefits.category": kw}},
                                {"match": {"benefits.summary": kw}}
                            ]
                        }
                    }
                }
            })
        
        body = {
            "size": size,
            "_source": True,
            "query": {"bool": {"should": should_clauses, "minimum_should_match": 1}}
        }
        
        try:
            resp = self.client.search(index=INDEX_NAME, body=body)
            hits = resp["hits"]["hits"]
            print(f"âœ… [ES] Found {len(hits)} cards matching keywords.")
            return [{"_id": h["_id"], "_source": h["_source"]} for h in hits]
        except Exception as e:
            print(f"âŒ [ES Error] {e}")
            return []

class LLMClient:
    """[ê³µí†µ] LLM API í˜¸ì¶œê¸°"""
    
    @staticmethod
    @traceable(run_type="llm", name="HF_Inference_API") # LangSmith: LLM í˜¸ì¶œë¡œ ì¸ì‹
    def call_api(messages: List[Dict], temperature=0.1) -> str:
        print("ğŸ¤– [LLM] Calling Inference API...")
        headers = {"Authorization": f"Bearer {HF_API_KEY}"}
        payload = {
            "model": MODEL_NAME, "messages": messages, 
            "max_tokens": 1000, "temperature": temperature,
            "response_format": {"type": "json_object"}
        }
        try:
            resp = requests.post("https://router.huggingface.co/v1/chat/completions", json=payload, headers=headers)
            resp.raise_for_status() # ì—ëŸ¬ ì²´í¬
            content = resp.json()['choices'][0]['message']['content']
            print("âœ… [LLM] Response received.")
            return content.replace("```json", "").replace("```", "").strip()
        except Exception as e:
            print(f"âŒ [LLM Error] {e}")
            return '{"recommendation_summary": {"recommended_card": "Error", "selection_reason": "LLM Error"}, "card_comparison_list": []}'

# ============================================================
# [Module 2] ì±—ë´‡ìš© íŒŒì´í”„ë¼ì¸ (Interactive)
# ============================================================

class ChatbotPipeline:
    def __init__(self):
        self.retriever = ESMultiRetriever()

    @traceable(run_type="tool", name="Query_Analyzer")
    def _analyze_query(self, user_query: str) -> Dict:
        """LLMì„ ì‚¬ìš©í•´ ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì˜ë„(í‚¤ì›Œë“œ, ê¸ˆì•¡) ì¶”ì¶œ"""
        prompt = f"""
        ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ JSONìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
        ì§ˆë¬¸: "{user_query}"
        
        ì¶œë ¥ í•„ë“œ:
        - keywords: í˜œíƒ ê´€ë ¨ í•µì‹¬ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["í†µì‹ ", "ìŠ¤íƒ€ë²…ìŠ¤"])
        - spend: ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ì›” ì‚¬ìš© ê¸ˆì•¡(ìˆ«ì). ì–¸ê¸‰ ì—†ìœ¼ë©´ 0.
        
        ì˜ˆì‹œ:
        {{"keywords": ["í¸ì˜ì ", "êµí†µ"], "spend": 300000}}
        """
        try:
            res_str = LLMClient.call_api([{"role": "user", "content": prompt}])
            return json.loads(res_str)
        except:
            return {"keywords": [user_query], "spend": 0}

    @traceable(run_type="chain", name="Chatbot_Pipeline") # LangSmith: ì „ì²´ ì²´ì¸
    def run(self, user_query: str) -> Dict:
        # 1. ë¶„ì„
        intent = self._analyze_query(user_query)
        keywords = intent.get("keywords", [])
        user_spend = intent.get("spend") or 500000
        
        logger.info(f"[Chatbot] Query: {user_query} -> Intent: {intent}")

        # 2. ê²€ìƒ‰
        candidates = self.retriever.search_by_coverage(keywords, size=100)

        # 3. ê³„ì‚° ë° ì •ë ¬
        scored = []
        for cand in candidates:
            src = cand["_source"]
            res = BenefitCalculator.calculate(src, user_spend, keywords)
            scored.append({
                "card_name": src["card_name"],
                "score": res["score"],
                "info": res["matched_info"],
                "summary": src["benefits"][0]["summary"] if src["benefits"] else ""
            })
        
        scored.sort(key=lambda x: x["score"], reverse=True)
        top_3 = scored[:3]

        return {"top_3": top_3, "raw_intent": intent}

# ============================================================
# [Module 3] ML/Persona íŒŒì´í”„ë¼ì¸ (Batch/Survey)
# ============================================================

class MLPersonaPipeline:
    def __init__(self):
        self.retriever = ESMultiRetriever()

    @traceable(run_type="chain", name="ML_Persona_Pipeline") # LangSmith: ì „ì²´ ì²´ì¸
    def run(self, cluster_id: int, category_codes: List[str]) -> Dict:
        # 1. ì„¤ì • ë¡œë“œ
        if cluster_id not in PERSONA_CLUSTERS:
            print(f"âŒ [Pipeline] Invalid Cluster ID: {cluster_id}")
            raise ValueError("Invalid Cluster ID")
        
        persona = PERSONA_CLUSTERS[cluster_id]
        user_spend = persona["avg_spend"]
        
        # í‚¤ì›Œë“œ ê²°í•©
        user_cats_kr = map_codes_to_korean(category_codes)
        search_keywords = list(set(persona["base_keywords"] + user_cats_kr))

        print(f"ğŸ§© [Pipeline] Cluster {cluster_id} ({persona['name_kr']}) detected.")
        print(f"ğŸ’° [Pipeline] Target Spend: {user_spend} KRW")
        print(f"ğŸ”‘ [Pipeline] Search Keywords: {search_keywords}")

        # 2. ê²€ìƒ‰
        candidates = self.retriever.search_by_coverage(search_keywords, size=150)

        # 3. ê³„ì‚° ë° ì •ë ¬
        scored = []
        print("ğŸ§® [Pipeline] Calculating benefits for candidates...")
        for cand in candidates:
            src = cand["_source"]
            res = BenefitCalculator.calculate(src, user_spend, user_cats_kr)
            
            scored.append({
                "card_id": src["card_id"],
                "card_name": src["card_name"],
                "final_score": res["score"],
                "matched_info": res["matched_info"],
                "summary_text": src["benefits"][0]["summary"] if src["benefits"] else ""
            })
        
        scored.sort(key=lambda x: x["final_score"], reverse=True)
        top_3 = scored[:3]

        print(f"ğŸ† [Pipeline] Top 3 Candidates Selected:")
        for idx, card in enumerate(top_3):
            print(f"   {idx+1}. {card['card_name']} (Score: {card['final_score']:.0f})")

        # 4. JSON ìƒì„± ìš”ì²­
        prompt = f"""
        ë‹¹ì‹ ì€ ì‹ ìš©ì¹´ë“œ ì¶”ì²œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ JSONì„ ìƒì„±í•˜ì„¸ìš”.
        
        [ì‚¬ìš©ì í”„ë¡œí•„]
        - ìœ í˜•: {persona['name_kr']}
        - ì›” ì†Œë¹„ì•¡: {user_spend}ì›
        - ì„ í˜¸ ì¹´í…Œê³ ë¦¬: {', '.join(user_cats_kr)}

        [ì¶”ì²œ ì¹´ë“œ Top 3]
        {json.dumps(top_3, ensure_ascii=False)}
        
        [ì‘ì„± ê·œì¹™]
        1. 'recommendation_summary': 1ìœ„ ì¹´ë“œë¥¼ ì¶”ì²œí•˜ê³ , ì‚¬ìš©ì ìœ í˜•({persona['name_kr']})ê³¼ ì„ í˜¸ ì¹´í…Œê³ ë¦¬({', '.join(user_cats_kr)})ë¥¼ ì–¸ê¸‰í•˜ë©° ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”.
        2. 'card_comparison_list': 3ê°œ ì¹´ë“œ ê°ê°ì— ëŒ€í•´ ì™œ ì´ ì¹´ë“œê°€ í›„ë³´ì— ì˜¬ëëŠ”ì§€ ê°„ëµíˆ ì„¤ëª…í•˜ì„¸ìš”.
        
        JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.
        """
        
        final_json_str = LLMClient.call_api([{"role": "user", "content": prompt}])
        
        try:
            llm_result = json.loads(final_json_str)
            
            # [í•µì‹¬ ìˆ˜ì •] LLM ê²°ê³¼ì— ì •í™•í•œ card_idì™€ card_name ì£¼ì… (ID ë§¤í•‘ ë³´ì •)
            # top_3 ë¦¬ìŠ¤íŠ¸ì˜ ìˆœì„œì™€ LLMì´ ìƒì„±í•œ ë¦¬ìŠ¤íŠ¸ ìˆœì„œê°€ ê°™ë‹¤ê³  ê°€ì •í•˜ê³  IDë¥¼ ë®ì–´ì”Œì›ë‹ˆë‹¤.
            if "card_comparison_list" in llm_result:
                for idx, item in enumerate(llm_result["card_comparison_list"]):
                    if idx < len(top_3):
                        # Pythonì´ ê³„ì‚°í•œ ì •í™•í•œ IDì™€ ì´ë¦„ì„ ì£¼ì…
                        item["card_id"] = top_3[idx]["card_id"]
                        item["card_name"] = top_3[idx]["card_name"]
                        item["card_company"] = top_3[idx].get("card_company", "ì¹´ë“œì‚¬") # í•„ìš”ì‹œ ì¶”ê°€
                        
            return llm_result

        except json.JSONDecodeError:
            print("âš ï¸ [Pipeline] LLM JSON Parsing Failed. Returning Raw Text.")
            return {"raw_response": final_json_str}

# ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
if __name__ == "__main__":
    ml_pipeline = MLPersonaPipeline()
    chatbot_pipeline = ChatbotPipeline() # ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ë„ ìƒì„± (í•„ìš”ì‹œ ì‚¬ìš©)

    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì˜ˆì‹œ)
    # result = ml_pipeline.run(cluster_id=0, category_codes=["OTT", "ê³µí•­ë¼ìš´ì§€"])
    # print(json.dumps(result, indent=2, ensure_ascii=False))

# ============================================================
# ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
# ============================================================
chatbot_pipeline = ChatbotPipeline()
ml_pipeline = MLPersonaPipeline()

# import os
# import json
# import logging
# import re
# from typing import List, Dict, Any, Optional
# from elasticsearch import Elasticsearch
# from dotenv import load_dotenv
# import requests

# # ë°ì´í„° ëª¨ë“ˆ (MLìš©)
# # ìˆ˜ì • í›„ (FastAPI ì‹¤í–‰ ìœ„ì¹˜ì¸ app ê¸°ì¤€ ì ˆëŒ€ ê²½ë¡œ ê¶Œì¥)
# try:
#     from app.rag.data.category_mappings import map_codes_to_korean
#     from app.rag.data.cluster_definitions import PERSONA_CLUSTERS
# except ImportError:
#     # ë¡œì»¬ í…ŒìŠ¤íŠ¸ ë“±ì„ ìœ„í•œ ìƒëŒ€ ê²½ë¡œ Fallback
#     from .data.category_mappings import map_codes_to_korean
#     from .data.cluster_definitions import PERSONA_CLUSTERS

# load_dotenv()

# # ì„¤ì •
# ELASTICSEARCH_URL = os.getenv("ELASTICSEARCH_URL", "http://localhost:9200")
# INDEX_NAME = "credit_cards_nested_v1"
# HF_API_KEY = os.getenv("HF_API_KEY")
# MODEL_NAME = "meta-llama/Llama-3.1-8B-Instruct:novita"

# logger = logging.getLogger("CardPipeline")
# logger.setLevel(logging.INFO)

# # ============================================================
# # [Module 1] ê³µí†µ ìœ í‹¸ë¦¬í‹° (ê³„ì‚°ê¸° & ES ê²€ìƒ‰ê¸° & LLM)
# # ============================================================

# class BenefitCalculator:
#     """[ê³µí†µ] ì¹´ë“œ í˜œíƒ ê¸ˆì•¡ ê³„ì‚°ê¸°"""
#     @staticmethod
#     def calculate(card_source: Dict, user_spend: int, preferred_keywords: List[str]) -> Dict:
#         total_benefit_krw = 0
#         matched_details = []

#         for ben in card_source.get("benefits", []):
#             summary = ben.get("summary", "")
#             category = ben.get("category", "")
#             tiers = ben.get("tiers", [])

#             # 1. Tiersì—ì„œ ì‹¤ì  ì¡°ê±´ ì¶©ì¡±í•˜ëŠ” ê°€ì¥ ë†’ì€ êµ¬ê°„ ì°¾ê¸°
#             sorted_tiers = sorted(tiers, key=lambda x: x.get("previous_min_spend", 0))
#             applied_tier = None
#             for tier in sorted_tiers:
#                 if user_spend >= tier.get("previous_min_spend", 0):
#                     applied_tier = tier
#                 else:
#                     break 
            
#             if not applied_tier: continue

#             # 2. í˜œíƒ ê¸ˆì•¡ ì‚°ì •
#             val = 0
#             if applied_tier.get("unit") == "%":
#                 # ê°€ì •: í•´ë‹¹ ì˜ì—­ ì†Œë¹„ ë¹„ì¤‘ 10%
#                 val = (user_spend * 0.1) * applied_tier.get("rate", 0)
#             elif applied_tier.get("unit") == "KRW":
#                 val = applied_tier.get("rate", 0)

#             # 3. ì„ í˜¸ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ (1.5ë°°)
#             is_preferred = any(pk in category or pk in summary for pk in preferred_keywords)
#             if is_preferred:
#                 val *= 1.5
#                 matched_details.append(f"{category}(â˜…)")
#             else:
#                 matched_details.append(category)
            
#             total_benefit_krw += val

#         return {"score": total_benefit_krw, "matched_info": ", ".join(list(set(matched_details)))}

# class ESMultiRetriever:
#     """[ê³µí†µ] Elasticsearch ê²€ìƒ‰ê¸°"""
#     def __init__(self):
#         self.client = Elasticsearch(ELASTICSEARCH_URL)

#     def search_by_coverage(self, keywords: List[str], size: int = 150) -> List[Dict]:
#         should_clauses = []
#         for kw in keywords:
#             should_clauses.append({
#                 "nested": {
#                     "path": "benefits",
#                     "score_mode": "sum",
#                     "query": {
#                         "bool": {
#                             "should": [
#                                 {"match": {"benefits.category": kw}},
#                                 {"match": {"benefits.summary": kw}}
#                             ]
#                         }
#                     }
#                 }
#             })
        
#         body = {
#             "size": size,
#             "_source": True,
#             "query": {"bool": {"should": should_clauses, "minimum_should_match": 1}}
#         }
        
#         try:
#             resp = self.client.search(index=INDEX_NAME, body=body)
#             return [{"_id": h["_id"], "_source": h["_source"]} for h in resp["hits"]["hits"]]
#         except Exception as e:
#             logger.error(f"ES Error: {e}")
#             return []

# class LLMClient:
#     """[ê³µí†µ] LLM API í˜¸ì¶œê¸°"""
#     @staticmethod
#     def call_api(messages: List[Dict], temperature=0.1) -> str:
#         headers = {"Authorization": f"Bearer {HF_API_KEY}"}
#         payload = {
#             "model": MODEL_NAME, "messages": messages, 
#             "max_tokens": 1000, "temperature": temperature,
#             "response_format": {"type": "json_object"}
#         }
#         resp = requests.post("https://router.huggingface.co/v1/chat/completions", json=payload, headers=headers)
#         content = resp.json()['choices'][0]['message']['content']
#         # JSON ë¬¸ìì—´ ì •ì œ
#         return content.replace("```json", "").replace("```", "").strip()

# # ============================================================
# # [Module 2] ì±—ë´‡ìš© íŒŒì´í”„ë¼ì¸ (Interactive)
# # ============================================================

# class ChatbotPipeline:
#     def __init__(self):
#         self.retriever = ESMultiRetriever()

#     def _analyze_query(self, user_query: str) -> Dict:
#         """LLMì„ ì‚¬ìš©í•´ ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì˜ë„(í‚¤ì›Œë“œ, ê¸ˆì•¡) ì¶”ì¶œ"""
#         prompt = f"""
#         ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ JSONìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.
#         ì§ˆë¬¸: "{user_query}"
        
#         ì¶œë ¥ í•„ë“œ:
#         - keywords: í˜œíƒ ê´€ë ¨ í•µì‹¬ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["í†µì‹ ", "ìŠ¤íƒ€ë²…ìŠ¤"])
#         - spend: ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ì›” ì‚¬ìš© ê¸ˆì•¡(ìˆ«ì). ì–¸ê¸‰ ì—†ìœ¼ë©´ 0.
        
#         ì˜ˆì‹œ:
#         {{"keywords": ["í¸ì˜ì ", "êµí†µ"], "spend": 300000}}
#         """
#         try:
#             res_str = LLMClient.call_api([{"role": "user", "content": prompt}])
#             return json.loads(res_str)
#         except:
#             return {"keywords": [user_query], "spend": 0}

#     def run(self, user_query: str) -> Dict:
#         """
#         [ì±—ë´‡ ì§„ì…ì ]
#         1. ì§ˆë¬¸ ë¶„ì„ -> 2. ê²€ìƒ‰ -> 3. ê³„ì‚° -> 4. ê²°ê³¼ ë¦¬í„´
#         """
#         # 1. ë¶„ì„
#         intent = self._analyze_query(user_query)
#         keywords = intent.get("keywords", [])
#         user_spend = intent.get("spend") or 500000 # ê¸°ë³¸ê°’ 50ë§Œì›
        
#         logger.info(f"[Chatbot] Query: {user_query} -> Intent: {intent}")

#         # 2. ê²€ìƒ‰
#         candidates = self.retriever.search_by_coverage(keywords, size=100)

#         # 3. ê³„ì‚° ë° ì •ë ¬
#         scored = []
#         for cand in candidates:
#             src = cand["_source"]
#             res = BenefitCalculator.calculate(src, user_spend, keywords)
#             scored.append({
#                 "card_name": src["card_name"],
#                 "score": res["score"],
#                 "info": res["matched_info"],
#                 "summary": src["benefits"][0]["summary"]
#             })
        
#         scored.sort(key=lambda x: x["score"], reverse=True)
#         top_3 = scored[:3]

#         # 4. ì±—ë´‡ìš© ë‹µë³€ ìƒì„± (LLMì—ê²Œ ìì—°ì–´ ìš”ì•½ ìš”ì²­)
#         final_prompt = f"""
#         ì‚¬ìš©ì ì§ˆë¬¸: "{user_query}"
#         ì¶”ì²œ ê²°ê³¼: {json.dumps(top_3, ensure_ascii=False)}
        
#         ìœ„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê²Œ Top 3 ì¹´ë“œë¥¼ ì¶”ì²œí•˜ëŠ” ë‹µë³€ì„ ì‘ì„±í•´ì¤˜.
#         JSON í˜•ì‹ì´ ì•„ë‹ˆë¼ ëŒ€í™”ì²´ í…ìŠ¤íŠ¸ë¡œ ì‘ì„±í•´.
#         """
#         # ì—¬ê¸°ì„œëŠ” JSONì´ ì•„ë‹Œ ì¼ë°˜ í…ìŠ¤íŠ¸ ëª¨ë“œë¡œ í˜¸ì¶œí•œë‹¤ê³  ê°€ì • (ì½”ë“œ ìƒëµ)
#         return {"top_3": top_3, "raw_intent": intent}


# # ============================================================
# # [Module 3] ML/Persona íŒŒì´í”„ë¼ì¸ (Batch/Survey)
# # ============================================================

# class MLPersonaPipeline:
#     def __init__(self):
#         self.retriever = ESMultiRetriever()

#     def run(self, cluster_id: int, category_codes: List[str]) -> Dict:
#         """
#         [ML/ì„¤ë¬¸ ì§„ì…ì ]
#         1. í˜ë¥´ì†Œë‚˜ Lookup -> 2. ê²€ìƒ‰ -> 3. ê³„ì‚° -> 4. JSON í¬ë§· ì‘ë‹µ
#         """
#         # 1. ì„¤ì • ë¡œë“œ
#         if cluster_id not in PERSONA_CLUSTERS:
#             raise ValueError("Invalid Cluster ID")
        
#         persona = PERSONA_CLUSTERS[cluster_id]
#         user_spend = persona["avg_spend"]
        
#         # í‚¤ì›Œë“œ ê²°í•© (Cluster Keywords + User Categories)
#         user_cats_kr = map_codes_to_korean(category_codes)
#         search_keywords = list(set(persona["keywords"] + user_cats_kr))

#         logger.info(f"[ML] Cluster: {cluster_id}, Spend: {user_spend}, Keys: {search_keywords}")

#         # 2. ê²€ìƒ‰
#         candidates = self.retriever.search_by_coverage(search_keywords, size=150)

#         # 3. ê³„ì‚° ë° ì •ë ¬
#         scored = []
#         for cand in candidates:
#             src = cand["_source"]
#             # user_cats_kr(ì‚¬ìš©ìê°€ ì§ì ‘ ì°ì€ ì¹´í…Œê³ ë¦¬)ì—ë§Œ ê°€ì¤‘ì¹˜ ë¶€ì—¬
#             res = BenefitCalculator.calculate(src, user_spend, user_cats_kr)
            
#             scored.append({
#                 "card_id": src["card_id"],
#                 "card_name": src["card_name"],
#                 "final_score": res["score"],
#                 "matched_info": res["matched_info"],
#                 "summary_text": src["benefits"][0]["summary"]
#             })
        
#         scored.sort(key=lambda x: x["final_score"], reverse=True)
#         top_3 = scored[:3]

#         # 4. JSON ìƒì„± ìš”ì²­ (êµ¬ì¡°í™”ëœ ì¶œë ¥)
#         prompt = f"""
#         [í”„ë¡œí•„] {persona['name']}, ì›” {user_spend}ì›
#         [í›„ë³´] {json.dumps(top_3, ensure_ascii=False)}
        
#         ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ recommendation_summary, card_comparison_list í˜•íƒœì˜ JSONì„ ìƒì„±í•´.
#         """
#         final_json_str = LLMClient.call_api([{"role": "user", "content": prompt}])
#         return json.loads(final_json_str)

