import json
import os
import sys
import time
from tqdm import tqdm

# [ì„¤ì •] rag ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from rag.chatbot_pipeline import run_pipeline

# í‰ê°€ ë°ì´í„°ì…‹ ê²½ë¡œ
# DATASET_PATH = "data/evaluation_dataset.json"
DATASET_PATH ="data/evaluation_dataset_complex_top100_generated.json"

def calculate_metrics(k=3):
    if not os.path.exists(DATASET_PATH):
        print("âŒ í‰ê°€ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤. generate_dataset.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    with open(DATASET_PATH, "r", encoding="utf-8") as f:
        eval_data = json.load(f)

    print(f"ğŸš€ RAG ì„±ëŠ¥ í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. (Top-K: {k}, Total Queries: {len(eval_data)})")
    print("-" * 60)
    print(f"{'Type':<10} | {'Query':<40} | {'Result':<10} | {'Rank'}")
    print("-" * 60)

    total_count = 0
    hit_count = 0
    mrr_sum = 0
    
    # íƒ€ì…ë³„ í†µê³„
    type_stats = {"Simple": {"hit": 0, "total": 0}, "Complex": {"hit": 0, "total": 0}}

    for item in tqdm(eval_data):
        query = item['query']
        ground_truth_ids = set(map(str, item['ground_truth_ids'])) # ë¬¸ìì—´ë¡œ í†µì¼
        q_type = item['type']
        
        try:
            # RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            results = run_pipeline(query) 
            
            # ê²°ê³¼ì—ì„œ ID ì¶”ì¶œ (Top-K)
            # resultsëŠ” dict listë¼ê³  ê°€ì • [{'card_id': ...}, ...]
            recommended_ids = [str(r.get('card_id') or r.get('id')) for r in results[:k]]
            
            # ì •ë‹µ í™•ì¸
            is_hit = False
            rank = 0
            
            for idx, rec_id in enumerate(recommended_ids):
                if rec_id in ground_truth_ids:
                    is_hit = True
                    rank = idx + 1
                    break
            
            # ì§€í‘œ ì—…ë°ì´íŠ¸
            total_count += 1
            type_stats[q_type]["total"] += 1
            
            if is_hit:
                hit_count += 1
                mrr_sum += 1 / rank
                type_stats[q_type]["hit"] += 1
                print(f"{q_type:<10} | {query[:38]:<40} | âœ… HIT     | {rank}")
            else:
                print(f"{q_type:<10} | {query[:38]:<40} | âŒ MISS    | -")
                
        except Exception as e:
            print(f"Error processing query '{query}': {e}")

    # --- ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥ ---
    hit_rate = (hit_count / total_count) * 100 if total_count > 0 else 0
    mrr = mrr_sum / total_count if total_count > 0 else 0
    
    print("\n" + "=" * 50)
    print("ğŸ“Š [Final Evaluation Report]")
    print("=" * 50)
    print(f"ğŸ¯ Overall Hit Rate @ {k} : {hit_rate:.2f}%")
    print(f"ğŸ¥‡ Overall MRR          : {mrr:.4f}")
    print("-" * 50)
    
    # íƒ€ì…ë³„ ìƒì„¸ ê²°ê³¼
    for t, stat in type_stats.items():
        t_hit_rate = (stat['hit'] / stat['total'] * 100) if stat['total'] > 0 else 0
        print(f"ğŸ”¹ {t:<10} Hit Rate    : {t_hit_rate:.2f}% ({stat['hit']}/{stat['total']})")
    print("=" * 50)

    # ë°œí‘œ ìë£Œìš© í…ìŠ¤íŠ¸ ìƒì„±
    print("\n[ğŸ“¢ ë°œí‘œ ìë£Œìš© ìš”ì•½ ë©˜íŠ¸]")
    print(f"\"ì´ {total_count}ê°œì˜ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬(ë‹¨ìˆœ/ë³µí•© í˜¼í•©)ì— ëŒ€í•´ í‰ê°€ë¥¼ ì§„í–‰í•œ ê²°ê³¼,")
    print(f"ìƒìœ„ {k}ê°œ ì¶”ì²œ ë‚´ ì •ë‹µ í¬í•¨ ë¹„ìœ¨ì¸ Hit RateëŠ” {hit_rate:.1f}%ë¥¼ ê¸°ë¡í–ˆìœ¼ë©°,")
    print(f"í‰ê· ì ìœ¼ë¡œ ì •ë‹µ ì¹´ë“œê°€ {1/mrr:.1f}ë²ˆì§¸ ìˆœìœ„ì— ë…¸ì¶œë˜ëŠ” {mrr:.2f}ì˜ MRR ì ìˆ˜ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤.\"")

if __name__ == "__main__":
    calculate_metrics(k=3)